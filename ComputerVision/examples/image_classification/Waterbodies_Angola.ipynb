{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "QpLIuz_JKF_S",
        "m5L9Z0PJKHVJ",
        "vo7EYCHt-2Xr",
        "nkgOSHVrKUtZ",
        "6CnZ25USKV-5"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates the task of image classification, in this case a classification of: reservoir | natural waterbody | shadows. The notebook includes the fine-tuning (training phase), testing and inference on a dataset of satellite images containing waterbodies in Angola. The fine-tuning is performed on a pre-trained CNN.\n",
        "\n",
        " The notebook follows these steps:\n",
        "\n",
        "*   General setup of DL environment in Google Colab (coupled to your Google Drive)\n",
        "*   All settings\n",
        "*   Fine-tuning the model with a training dataset\n",
        "*   Testing the fine-tuned model\n",
        "*   Inference: classification of waterbodies\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NxDbqYpWqlAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General setup"
      ],
      "metadata": {
        "id": "V9tE3EksuYbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade geopandas\n",
        "\n",
        "# Imports\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import itertools\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import geopandas as gpd\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "L8y4oimBubJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following line of code is a shell command executed within the notebook. It uses the '!' prefix to run a command as if it were in the terminal.\n",
        "!nvidia-smi\n",
        "\n",
        "# The 'nvidia-smi' command stands for NVIDIA System Management Interface. It is used to query and manage NVIDIA GPU devices.\n",
        "# Running this command displays information about the GPUs on your system, including utilization, memory usage, driver version, and more."
      ],
      "metadata": {
        "id": "xEzCC2XWuucz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access your (training, test and inference) data (you have to consent to everything to get it working..)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ibmZDgJjuv9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the AUTOTUNE option for automatic optimization and print the Tensorflow version\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "print(f\"Tensorflow version that is currently being used: {tf.__version__}\")"
      ],
      "metadata": {
        "id": "bdt3IUjcu0_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TPU if data is stored in the cloud\n",
        "tpu = None\n",
        "\n",
        "if tpu:\n",
        "  # If TPU is initialized, shut down the TPU system\n",
        "  tf.tpu.experimental.shutdown_tpu_system(tpu)\n",
        "\n",
        "try:\n",
        "  # Attempt to detect and initialize a TPU\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "  # If no TPU is found, fall back to default strategy for CPU or single GPU\n",
        "  strategy = tf.distribute.get_strategy() # default strategy for CPU and single GPU"
      ],
      "metadata": {
        "id": "BhnCcCD-u2ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ],
      "metadata": {
        "id": "UnV-8vfjucZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Paths and files"
      ],
      "metadata": {
        "id": "0jdN97B-zYeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive directory that stores the downloaded data and scripts (later changeo to name repository folder: image_classification)\n",
        "dir_gdrive = r'/content/drive/MyDrive/AngolaTrainingData'\n",
        "\n",
        "# Datasets, model and scripts\n",
        "dir_data = f'{dir_gdrive}/00_data'\n",
        "dir_model = f'{dir_gdrive}/01_model'\n",
        "dir_scripts = f'{dir_gdrive}/02_src'\n",
        "sys.path.append(dir_scripts)\n",
        "\n",
        "# Coordinates of waterbodies\n",
        "filename_geojson = 'blobdetected_angola_blobs_filtered_full'\n",
        "\n",
        "# Print system path\n",
        "sys.path"
      ],
      "metadata": {
        "id": "D8lOPYaBueHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model (pre-trained CNN)"
      ],
      "metadata": {
        "id": "z5yA8L7nzaGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"efficientnetv2-xl-21k\"\n",
        "model_handle = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/feature_vector/2\""
      ],
      "metadata": {
        "id": "wWhUmL9izkVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "ZFGFF890Q12k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1.5 / 255)\n",
        "do_data_augmentation = True\n",
        "\n",
        "IMAGE_SIZE = (512, 512) # this is the image shape required for the keras model (or what): so if the images have different shapes (that is the case for the vortex images. TODO: the images need to be reshaped to (512, 512); there is a keras function for this)\n",
        "BATCH_SIZE = 16         # TODO: check with Antonio: he used batch size 20 for the testing and inference\n",
        "EPOCHS = 300\n",
        "\n",
        "drop_out_rate = 0.3\n",
        "learning_rate = 0.005\n",
        "momentum = 0.9\n",
        "label_smoothing = 0.1\n",
        "metrics = ['accuracy']"
      ],
      "metadata": {
        "id": "DYH1AM6qQ1JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune model"
      ],
      "metadata": {
        "id": "K-lYWQMeukEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Ec8XV2_PKBzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build dataset"
      ],
      "metadata": {
        "id": "QpLIuz_JKF_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import build_training_dataset, augment_data\n",
        "\n",
        "# Training data\n",
        "dir_data_training = os.path.join(dir_data, 'training') # dir_data_training = f'{dir_gdrive}/AngolaFullTraining'\n",
        "ds_train_r, class_names, ds_train_size = build_training_dataset(dir_data_training, \"training\", IMAGE_SIZE, BATCH_SIZE)\n",
        "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
        "preprocessing_model = augment_data(do_data_augmentation, preprocessing_model)\n",
        "ds_train = ds_train_r.map(lambda images, labels:(preprocessing_model(images), labels))\n",
        "\n",
        "# Validation data\n",
        "ds_val, class_names, ds_val_size = build_training_dataset(dir_data_training, \"validation\", IMAGE_SIZE, BATCH_SIZE)\n",
        "ds_val = ds_val.map(lambda images, labels:(normalization_layer(images), labels))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B2--BgXzKqU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import plot_training_data\n",
        "\n",
        "# Plot a few images from the training dataset to check\n",
        "fig_train = plot_training_data(ds_train, 8)"
      ],
      "metadata": {
        "id": "-u-ImF1fz2yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few images from the validation dataset to check\n",
        "fig_val = plot_training_data(ds_val, 8)"
      ],
      "metadata": {
        "id": "Xv59esNiOTvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "m5L9Z0PJKHVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Composition of the model of different layers (input layer, original encoder layers, dense layers that are trained with the satellite imagery dataset)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(model_handle, trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=drop_out_rate),\n",
        "    tf.keras.layers.Dense(len(class_names),\n",
        "    kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()\n",
        "\n",
        "# Configure the model for training by specifiying the optimizer (Stochastic Gradient Descent), loss function and metrics to be used\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=label_smoothing),\n",
        "  metrics=metrics)"
      ],
      "metadata": {
        "id": "JnydajEL83sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "vo7EYCHt-2Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual training of the dense layers in the sequenced model\n",
        "hist = model.fit(\n",
        "    ds_train,\n",
        "    epochs=EPOCHS, steps_per_epoch=ds_train_size // BATCH_SIZE,\n",
        "    validation_data=ds_val,\n",
        "    validation_steps=ds_val_size // BATCH_SIZE).history"
      ],
      "metadata": {
        "id": "orYr0LJb-2G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results of the training\n",
        "from fine_tune import plot_training_results\n",
        "\n",
        "fig = plot_training_results(hist)"
      ],
      "metadata": {
        "id": "eU_c-6HC_QVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model (and its history object) to use for inference\n",
        "from fine_tune import save_model\n",
        "\n",
        "save_model(model, dir_model, model_name, hist)"
      ],
      "metadata": {
        "id": "DfYEsx3TOprb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "hhE7FlZMKDcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build dataset"
      ],
      "metadata": {
        "id": "nkgOSHVrKUtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_data_testing = os.path.join(dir_data, 'testing') # dir_data_testing = f'{dir_gdrive}/testing3class'\n",
        "\n",
        "ds_test = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_data_testing,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE, #25?\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "ds_test = ds_test.map(lambda images, labels:(normalization_layer(images), labels))"
      ],
      "metadata": {
        "id": "QvV5bv8lfg_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ],
      "metadata": {
        "id": "6CnZ25USKV-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fine-tuned model\n",
        "# model = keras.models.load_model(os.path.join(dir_model, f'{model_name}_finetuned.h5'),\n",
        "#        custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "model = keras.models.load_model(r'/content/drive/MyDrive/AngolaTrainingData/model_EffNetV2_retrainedAngola_3class.h5',\n",
        "       custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "metadata": {
        "id": "amaJFar9k74f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from testing import test_model\n",
        "\n",
        "labels_test, predictions_test = test_model(model, ds_test)\n",
        "\n",
        "acc = accuracy_score(labels_test, predictions_test)\n",
        "cm = confusion_matrix(labels_test, predictions_test)\n",
        "\n",
        "print(f\"Accuracy: {acc}\")\n",
        "print(f\"Confusion matrix: \\n{cm}\")"
      ],
      "metadata": {
        "id": "GLQYamPuVBQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plot import plot_test_results\n",
        "\n",
        "fig = plot_test_results(model, ds_test)"
      ],
      "metadata": {
        "id": "6YKpD0K0GfUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "6VIzPrEeunAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build dataset"
      ],
      "metadata": {
        "id": "UW6492CgKays"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inference import get_img_ids\n",
        "\n",
        "dir_data_inference = os.path.join(dir_data, 'inference') # dir_data_inference = f'{dir_gdrive}/AngolaPNGsZoom'\n",
        "\n",
        "ds_inf = tf.keras.utils.image_dataset_from_directory(\n",
        "    dir_data_inference,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE, #20?\n",
        "    shuffle = False,\n",
        "    label_mode=None,\n",
        "    labels=None)\n",
        "\n",
        "img_ids = get_img_ids(ds_inf)\n",
        "\n",
        "ds_inf = ds_inf.map(lambda images:(normalization_layer(images)))"
      ],
      "metadata": {
        "id": "yQ2spQGJflGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "DKnHCt0-Kcug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(dataset)\n",
        "y_pred = np.argmax(predictions, axis = 1)"
      ],
      "metadata": {
        "id": "03ENz2PWunzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show some results of the inference\n",
        "from inference import plot_inference_results\n",
        "\n",
        "fig = plot_inference_results(model, ds_inf)"
      ],
      "metadata": {
        "id": "a3VQe7ofy8CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link the waterbodies in the images to the coordinates of the blobs in the geojson file and save to a new geojson file\n",
        "from inference import link_waterbodies_coordinates, save_prediction_geojson\n",
        "\n",
        "data_coord = gpd.read_file(os.path.join(dir_data, f'{filename_geojson}.geojson'))\n",
        "pred_coord = linke_waterbodies_coordinates(img_ids, y_pred, data_coord)\n",
        "save_prediction_geojson(pred_coord, dir_data, filename_geojson)"
      ],
      "metadata": {
        "id": "J720prc5Szfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}